{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Generic\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Images\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "# import talos as ta\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, plot_confusion_matrix, roc_curve\n",
    "\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "\n",
    "# Keras\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.utils import print_summary\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.densenet import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_split = [0.7, 0.3, 0.0]\n",
    "input_shape = (224, 224, 3)\n",
    "seed = 1234\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "### Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Classes and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CheXnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chexNet weights\n",
    "chexnet_weights = '/home/ygala/TFM_UOC/scripts/chexnet/best_weights.h5'\n",
    "\n",
    "def chexnet_preprocess_input(value):\n",
    "    return preprocess_input(value)\n",
    "\n",
    "\n",
    "def get_chexnet_model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    base_weights = 'imagenet'\n",
    "\n",
    "    # create the base pre-trained model\n",
    "    base_model = DenseNet121(\n",
    "        include_top=False,\n",
    "        input_tensor=img_input,\n",
    "        input_shape=input_shape,\n",
    "        weights=base_weights,\n",
    "        pooling='avg'\n",
    "    )\n",
    "\n",
    "    x = base_model.output\n",
    "    # add a logistic layer -- let's say we have 14 classes\n",
    "    predictions = Dense(\n",
    "        14,\n",
    "        activation='sigmoid',\n",
    "        name='predictions')(x)\n",
    "\n",
    "    # this is the model we will use\n",
    "    model = Model(\n",
    "        inputs=img_input,\n",
    "        outputs=predictions,\n",
    "    )\n",
    "\n",
    "    # load chexnet weights\n",
    "    model.load_weights(chexnet_weights)\n",
    "\n",
    "    # return model\n",
    "    return base_model, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight(csv_file_path, target_class):\n",
    "    df = pd.read_csv(csv_file_path, sep=';')\n",
    "    total_counts = df.shape[0]\n",
    "    class_weight = []\n",
    "\n",
    "    ratio_pos = df.loc[(df[target_class] == 'Y')].shape[0] / total_counts\n",
    "    ratio_neg = df.loc[(df[target_class] == 'N')].shape[0] / total_counts\n",
    "    class_weight = np.array((ratio_pos, ratio_neg))\n",
    "        \n",
    "    return class_weight\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "def print_confidence_intervals(statistics):\n",
    "    df = pd.DataFrame(columns=[\"Mean AUC (CI 5%-95%)\"])\n",
    "    mean = statistics.mean()\n",
    "    max_ = np.quantile(statistics, .95)\n",
    "    min_ = np.quantile(statistics, .05)\n",
    "    df.loc[\"Exitus\"] = [\"%.2f (%.2f-%.2f)\" % (mean, min_, max_)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_model(learning_rate):\n",
    "    # get base model, model\n",
    "    base_model, chexnet_model = get_chexnet_model()\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    # Regularization layer\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Dense layer\n",
    "    x = Dense(128, \n",
    "              activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l1_l2(0.5, 0.0001))(x)\n",
    "    \n",
    "    # Regularization layer\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    \n",
    "    # add a logistic layer -- let's say we have 6 classes\n",
    "    predictions = Dense(\n",
    "        1,\n",
    "        activation='sigmoid')(x)\n",
    "\n",
    "    # this is the model we will use\n",
    "    model = Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=predictions,\n",
    "    )\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # initiate an Adam optimizer\n",
    "    opt = Adam(\n",
    "        lr=learning_rate,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        decay=0.0,\n",
    "        amsgrad=False\n",
    "    )\n",
    "\n",
    "    # Let's train the model using Adam\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=[metrics.BinaryAccuracy(name = \"acc\"),\n",
    "                metrics.AUC(name = \"auc\")])\n",
    "\n",
    "    return base_model, model\n",
    "\n",
    "\n",
    "class print_learning_rate(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        print(f'Learning rate = {K.eval(lr):.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafica_entrenamiento(tr_auc, val_auc, tr_loss, val_loss, best_i,\n",
    "                          figsize=(10,5), path_results = None):\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.subplot(1,2,1)\n",
    "    plt.plot(1+np.arange(len(tr_loss)), np.array(tr_loss))\n",
    "    plt.plot(1+np.arange(len(val_loss)), np.array(val_loss))\n",
    "    plt.plot(1+best_i, val_loss[best_i], 'or')\n",
    "    plt.title('loss del modelo', fontsize=18)\n",
    "    plt.ylabel('loss', fontsize=12)\n",
    "    plt.xlabel('época', fontsize=18)        \n",
    "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    \n",
    "    plt.plot(1+np.arange(len(tr_auc)),  np.array(tr_auc))\n",
    "    plt.plot(1+np.arange(len(val_auc)), np.array(val_auc))\n",
    "    plt.plot(1+best_i, val_auc[best_i], 'or')\n",
    "    plt.title('AUC', fontsize=18)\n",
    "    plt.ylabel('AUC', fontsize=12)\n",
    "    plt.xlabel('época', fontsize=18)    \n",
    "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    if (path_results != None):\n",
    "        plt.savefig(os.path.join(path_results, 'auc_loss.png'))\n",
    "    plt.show()\n",
    "    \n",
    "class TrainingPlot(Callback):\n",
    "    \n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Initialize the lists for holding the logs, losses and accuracies\n",
    "        self.losses = []\n",
    "        self.auc = []\n",
    "        self.val_losses = []\n",
    "        self.val_auc = []\n",
    "        self.logs = []\n",
    "    \n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):       \n",
    "       \n",
    "        \n",
    "        # Before plotting ensure at least 10 epochs have passed\n",
    "        if epoch > 20:\n",
    "             # Append the logs, losses and accuracies to the lists\n",
    "            self.logs.append(logs)        \n",
    "            self.auc.append(logs.get('auc'))        \n",
    "            self.val_auc.append(logs.get('val_auc'))\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            best_i = np.argmax(self.val_auc)\n",
    "            grafica_entrenamiento(self.auc, self.val_auc, self.losses, self.val_losses, best_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap(model, im, es_maligna, predictions):\n",
    "    \n",
    "\n",
    "\n",
    "    imag = np.reshape(im, (1, im.shape[0], im.shape[1], im.shape[2]))\n",
    "        \n",
    "    # This is the \"benign\" entry in the prediction vector\n",
    "    output = model.output[0, 0]\n",
    "    \n",
    "    # The is the output feature map of the last convolutional layer\n",
    "    last_conv_layer = model.get_layer('bn')\n",
    "    \n",
    "    # This is the gradient of the \"benign\" class with regard to\n",
    "    # the output feature map of last convolutional layer\n",
    "    grads = K.gradients(output, last_conv_layer.output)[0]\n",
    "    \n",
    "    \n",
    "    # This function allows us to access the values of the quantities we just defined:\n",
    "    # `pooled_grads` and the output feature map of the last convolutional layer\n",
    "    # given a sample image\n",
    "    iterate = K.function([model.input], [last_conv_layer.output, grads])\n",
    "    \n",
    "    # These are the values of these two quantities, as Numpy arrays,\n",
    "    # given our sample image\n",
    "    output, grads_val = iterate(imag)\n",
    "    conv_layer_output_value, pooled_grads_value = output[0, :], grads_val[0, :, :, :]   \n",
    "    \n",
    "   \n",
    "    \n",
    "      \n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    weights = np.mean(pooled_grads_value, axis=(0, 1))\n",
    "    cam = np.dot(conv_layer_output_value, weights)\n",
    "    heatmap = np.maximum(cam, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    plt.matshow(heatmap)\n",
    "    plt.show()\n",
    "    \n",
    "    # load the original image\n",
    "    img = imag[0]\n",
    "    \n",
    "    # Process CAM\n",
    "    cam = cv2.resize(cam, (img.shape[1], img.shape[0]), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()  \n",
    "\n",
    "\n",
    "    \n",
    "    # We resize the heatmap to have the same size as the original image\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # We convert the heatmap to RGB\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    \n",
    "    # We apply the heatmap to the original image\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    superimposed_img = heatmap * 0.8 / 255 + 0.8*img\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img, vmin=0, vmax=1)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(heatmap, vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(img,\n",
    "                       cmap='gray')\n",
    "    plt.imshow(cam, cmap='jet', alpha=min(0.5, predictions[0]))\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    print(\"- Probabilidad de Exitus:\", predictions[0])\n",
    "    print(\"-\", \"Clase real:\", \"No sobrevive\" if es_maligna else \"Sobrevive\")\n",
    "    print(\"\\n\\n\\n\")\n",
    "    return heatmap, superimposed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '/home/ygala/TFM_UOC/'\n",
    "path_images = os.path.join(path_root, 'data', 'covid_images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case_features = pd.read_csv(os.path.join(path_images, 'clean_data_1_filtered_2.csv'), sep=';');\n",
    "case_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 'survival'\n",
    "np.random.seed(seed)\n",
    "\n",
    "### Positive patient ids \n",
    "positive = case_features[case_features.survival.values == 'Y']\n",
    "positive_ids = positive.patientid.unique()\n",
    "\n",
    "### Negative patient ids \n",
    "negative = case_features[case_features.survival.values == 'N']\n",
    "negative_ids = negative.patientid.unique()\n",
    "n_negative_ids = len(negative_ids)\n",
    "\n",
    "### Test\n",
    "test_size = perc_split[2]*n_negative_ids\n",
    "test_ids = np.append(np.random.choice(positive_ids, size = math.floor(test_size), replace = False),\n",
    "                     np.random.choice(negative_ids, size = math.floor(test_size), replace = False))\n",
    "positive_ids = positive_ids[~np.isin(positive_ids, test_ids)]\n",
    "negative_ids = negative_ids[~np.isin(negative_ids, test_ids)]\n",
    "\n",
    "### Val\n",
    "val_size = perc_split[1]*n_negative_ids\n",
    "val_ids = np.append(np.random.choice(positive_ids, size = math.floor(val_size), replace = False),\n",
    "                     np.random.choice(negative_ids, size = math.floor(val_size), replace = False))\n",
    "positive_ids = positive_ids[~np.isin(positive_ids, val_ids)]\n",
    "negative_ids = negative_ids[~np.isin(negative_ids, val_ids)]\n",
    "\n",
    "### Train\n",
    "train_ids = np.append(positive_ids,\n",
    "                    negative_ids)\n",
    "\n",
    "# Split dataset based on patient ids\n",
    "case_features_train = case_features[case_features.patientid.isin(train_ids)]\n",
    "case_features_val = case_features[case_features.patientid.isin(val_ids)]\n",
    "# case_features_test = case_features[case_features.patientid.isin(test_ids)]\n",
    "\n",
    "# Selección del patrón de datos X y del target y\n",
    "ytrain = case_features_train[target_class]\n",
    "del case_features_train[target_class]\n",
    "Xtrain = case_features_train\n",
    "\n",
    "yval = case_features_val[target_class]\n",
    "del case_features_val[target_class]\n",
    "Xval = case_features_val\n",
    "\n",
    "ytest = case_features_test[target_class]\n",
    "del case_features_test[target_class]\n",
    "Xtest = case_features_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829\n",
      "94\n",
      "39\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(case_features_train[ytrain == \"Y\"].patientid.unique()))\n",
    "print(len(case_features_train[ytrain == \"N\"].patientid.unique()))\n",
    "print(len(case_features_val[yval == \"Y\"].patientid.unique()))\n",
    "print(len(case_features_val[yval == \"N\"].patientid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1278, 41)\n",
      "(1171, 40)\n",
      "(107, 40)\n"
     ]
    }
   ],
   "source": [
    "print(case_features.shape)\n",
    "print(case_features_train.shape)\n",
    "print(case_features_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y    1033\n",
      "N     138\n",
      "Name: survival, dtype: int64\n",
      "N    55\n",
      "Y    52\n",
      "Name: survival, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ytrain.value_counts())\n",
    "print(yval.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1171, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    # print('%0.2f%%' % float(100*i/Xtrain.shape[0]))\n",
    "    image_path = os.path.join(path_images, 'processed', Xtrain.iloc[i].filename)\n",
    "    imagen = Image.open(image_path)\n",
    "    imagen = np.asarray(imagen.convert(\"RGB\"))\n",
    "    imagen = resize(imagen,  input_shape)\n",
    "    X_train.append(imagen)\n",
    "\n",
    "X_train = np.stack(X_train, axis = 0)\n",
    "np.save(os.path.join(path_images, 'X_train.npy'), X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_val = []\n",
    "for i in range(Xval.shape[0]):\n",
    "    # print('%0.2f%%' % float(100*i/Xval.shape[0]))\n",
    "    image_path = os.path.join(path_images, 'processed', Xval.iloc[i].filename)\n",
    "    imagen = Image.open(image_path)\n",
    "    imagen = np.asarray(imagen.convert(\"RGB\"))\n",
    "    imagen = resize(imagen,  input_shape)\n",
    "    X_val.append(imagen)\n",
    "\n",
    "X_val = np.stack(X_val, axis = 0)\n",
    "np.save(os.path.join(path_images, 'X_val.npy'), X_val)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(Xtest.shape[0]):\n",
    "     # print('%0.2f%%' % float(100*i/Xtest.shape[0]))\n",
    "    image_path = os.path.join(path_images, 'processed', Xtest.iloc[i].filename)\n",
    "    imagen = Image.open(image_path)\n",
    "    imagen = np.asarray(imagen.convert(\"RGB\"))\n",
    "    imagen = resize(imagen,  input_shape)\n",
    "    X_test.append(imagen)\n",
    "\n",
    "X_test = np.stack(X_test, axis = 0)\n",
    "np.save(os.path.join(path_images, 'X_test.npy'), X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda/python-3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/miniconda/python-3.6/lib/python3.6/site-packages/pandas/core/generic.py:8765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "/usr/local/miniconda/python-3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1171,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[ytrain=='Y'] = 0\n",
    "ytrain[ytrain=='N'] = 1\n",
    "y_train = np.array(ytrain, dtype = np.int64)\n",
    "y_train.shape\n",
    "np.save(os.path.join(path_images, 'y_train.npy'), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda/python-3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/miniconda/python-3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(107,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yval[yval=='Y'] = 0\n",
    "yval[yval=='N'] = 1\n",
    "y_val = np.array(yval, dtype = np.int64)\n",
    "y_val.shape\n",
    "#np.save(os.path.join(path_images, 'y_val.npy'), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest[ytest=='Y'] = 0\n",
    "ytest[ytest=='N'] = 1\n",
    "y_test = np.array(ytest, dtype = np.int64)\n",
    "\n",
    "np.save(os.path.join(path_images, 'y_test.npy'), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(path_images, 'X_train.npy'))\n",
    "X_val = np.load(os.path.join(path_images, 'X_val.npy'))\n",
    "X_test = np.load(os.path.join(path_images, 'X_test.npy'))\n",
    "y_train = np.load(os.path.join(path_images, 'y_train.npy'))\n",
    "y_val = np.load(os.path.join(path_images, 'y_val.npy'))\n",
    "y_test = np.load(os.path.join(path_images, 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88215201 0.11784799]\n",
      "[0.48598131 0.51401869]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "ratio_pos = np.count_nonzero(y_train == 0) / len(y_train)\n",
    "ratio_neg = np.count_nonzero(y_train == 1) / len(y_train)\n",
    "class_weight_train = np.array((ratio_pos, ratio_neg))\n",
    "\n",
    "# val\n",
    "ratio_pos = np.count_nonzero(y_val == 0) / len(y_val)\n",
    "ratio_neg = np.count_nonzero(y_val == 1) / len(y_val)\n",
    "class_weight_val = np.array((ratio_pos, ratio_neg))\n",
    "\n",
    "# test\n",
    "ratio_pos = np.count_nonzero(y_test == 0) / len(y_test)\n",
    "ratio_neg = np.count_nonzero(y_test == 1) / len(y_test)\n",
    "class_weight_test= np.array((ratio_pos, ratio_neg))\n",
    "\n",
    "# Print\n",
    "print(class_weight_train)\n",
    "print(class_weight_val)\n",
    "print(class_weight_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(\n",
    "    os.getcwd(),\n",
    "    '../saved_models'\n",
    ")\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# This callback saves the weights of the model after each epoch\n",
    "checkpoint = ModelCheckpoint(\n",
    "    '../saved_models/weights.epoch_{epoch:02d}.hdf5',\n",
    "    monitor='val_loss', \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# This callback writes logs for TensorBoard\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='./Graph', \n",
    "    histogram_freq=0,  \n",
    "    write_graph=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_auc', patience=400, verbose=1, mode='max', restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=250, mode='min')\n",
    "\n",
    "\n",
    "callbacks_list = [early_stopping, plot_losses, print_lr]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed\n",
    "base_model, model = get_model(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show layers\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENTRENAMIENTO\n",
    "\n",
    "epochs = [ 10000]\n",
    "batch_size = [32, 64, 128]\n",
    "learning_rate = [0.1, 0.01, 0.001]\n",
    "\n",
    "previous_val_auc = 0\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for e in epochs:\n",
    "    for b in batch_size:\n",
    "        for l in learning_rate:\n",
    "            print(\"Numero de épocas\", e,\", batch size\", b,  \", learning rate\", l)\n",
    "\n",
    "            ###### ENTRENAMIENTO\n",
    "            out = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            steps_per_epoch=len(X_train) / b, \n",
    "                            epochs=e,\n",
    "                            class_weight=class_weight_train,\n",
    "                            callbacks = callbacks_list_augmented,       \n",
    "                            verbose=0)\n",
    "\n",
    "            train_loss = out.history['loss'][-1]\n",
    "            val_loss = out.history['val_loss'][-1]\n",
    "            train_auc = out.history['auc'][-1]\n",
    "            val_auc = out.history['val_auc'][-1]\n",
    "            stopped_epoch = my_callbacks.stopped_epoch\n",
    "            model = out.model\n",
    "            \n",
    "            res = pd.DataFrame([e, l, b, stopped_epoch, train_loss, val_loss, train_auc, val_auc])\n",
    "            df = pd.concat([df, res], axis=1)\n",
    "\n",
    "            df.to_csv('model_results34.csv') \n",
    "            \n",
    "            if(previous_val_auc < val_auc):\n",
    "                save_dir = os.path.join(\n",
    "                    os.getcwd(),\n",
    "                    '../model_results_y'\n",
    "                )\n",
    "                if not os.path.isdir(save_dir):\n",
    "                    os.makedirs(save_dir)\n",
    "                model.save('../../model_results_y/model.h5')\n",
    "                \n",
    "                previous_val_auc = val_auc\n",
    "                \n",
    "            for e in range(epochs):    \n",
    "                acum_tr_acc = acum_tr_acc + history.history['accuracy']\n",
    "                acum_val_acc = acum_val_acc + history.history['val_accuracy']\n",
    "\n",
    "                if len(acum_tr_acc) > 1:\n",
    "                    clear_output()\n",
    "                    grafica_entrenamiento(acum_tr_acc, acum_val_acc)\n",
    "                           \n",
    "df.index = ['epochs', 'learning_rate', 'batch_size',\n",
    "            'early_stopping', 'train_loss', 'val_loss', 'train_auc', 'val_auc']\n",
    "df.to_csv('model_results3.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(),'final_model_results')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model.save(os.path.join(save_dir, 'model.h5')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "pred_val = model.predict(X_val)\n",
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_train = roc_auc_score(y_true = y_train, y_score = pred_train)\n",
    "auc_val = roc_auc_score(y_true = y_val, y_score = pred_val)\n",
    "auc_test = roc_auc_score(y_true = y_test, y_score = pred_test)\n",
    "print('AUC train = %s - AUC val = %s - AUC test = %s' % (str(auc_train), str(auc_val), str(auc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels_train = (pred_train >= 0.5).astype(int)\n",
    "y_labels_val = (pred_val >= 0.5).astype(int)\n",
    "y_labels_test = (pred_test >= 0.5).astype(int)\n",
    "cm_train = confusion_matrix(y_pred = y_labels_train, y_true = y_train)\n",
    "cm_val = confusion_matrix(y_pred = y_labels_val, y_true = y_val)\n",
    "cm_test = confusion_matrix(y_pred = y_labels_test, y_true = y_test)\n",
    "print(cm_train)\n",
    "print(cm_val)\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.to_csv(os.path.join(save_dir, 'predictions', 'X_train.csv'))\n",
    "np.savetxt(os.path.join(save_dir, 'predictions', 'predictions_train_augmented.csv'), pred_train, delimiter=\";\")\n",
    "np.savetxt(os.path.join(save_dir, 'predictions','y_train.csv'), y_train, delimiter=\";\")\n",
    "Xval.to_csv(os.path.join(save_dir, 'predictions', 'X_val.csv'))\n",
    "np.savetxt(os.path.join(save_dir, 'predictions', 'predictions_val_augmented.csv'), pred_val, delimiter=\";\")\n",
    "np.savetxt(os.path.join(save_dir, 'predictions','y_val.csv'), y_val, delimiter=\";\")\n",
    "Xtest.to_csv(os.path.join(save_dir, 'predictions','X_test.csv'))\n",
    "np.savetxt(os.path.join(save_dir, 'predictions','predictions_test_augmented.csv'),pred_test, delimiter=\";\")\n",
    "np.savetxt(os.path.join(save_dir, 'predictions','y_test.csv'), y_test, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_CI_train = bootstrap_auc(y_train, pred_train, bootstraps = 100, fold_size = 1000,)\n",
    "AUC_CI_val = bootstrap_auc(y_val, pred_val, bootstraps = 100, fold_size = 1000)\n",
    "AUC_CI_test = bootstrap_auc(y_test, pred_test, bootstraps = 100, fold_size = 1000,)\n",
    "AUC_CI = print_confidence_intervals(AUC_CI_train,)\n",
    "AUC_CI = AUC_CI.append(print_confidence_intervals(AUC_CI_val), ignore_index=True)\n",
    "AUC_CI = AUC_CI.append(print_confidence_intervals(AUC_CI_test), ignore_index=True)\n",
    "AUC_CI.index = ['Train', 'Val', 'Test'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_train, tpr_train, threshold_train = roc_curve(y_train, pred_train)\n",
    "roc_auc_train = roc_auc_score(y_true = y_train, y_score = pred_train)\n",
    "fpr_val, tpr_val, threshold_val = roc_curve(y_val, pred_val)\n",
    "roc_auc_val = roc_auc_score(y_true = y_val, y_score = pred_val)\n",
    "# fpr_test, tpr_test, threshold_test = roc_curve(y_test, pred_test)\n",
    "# roc_auc_test = roc_auc_score(y_true = y_test, y_score = pred_test)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_train, tpr_train, 'r', label = 'AUC_train = %0.2f' % roc_auc_train)\n",
    "plt.plot(fpr_val, tpr_val, 'g', label = 'AUC_val = %0.2f' % roc_auc_val)\n",
    "#plt.plot(fpr_test, tpr_test, 'b', label = 'AUC_test = %0.2f' % roc_auc_test)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap / Gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test = X_test[:, 0:185, :, :]\n",
    "new_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argmax(pred_test)\n",
    "print('index ' + str(i));\n",
    "heat_map, superimposed_img = show_heatmap(model, new_X_test[i], y_test[i], pred_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argmin(pred_test)\n",
    "print('index ' + str(i));\n",
    "heat_map, superimposed_img = show_heatmap(model, new_X_test[i], y_test[i], pred_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.where(y_test == 1)[0]:\n",
    "    print('index ' + str(i));\n",
    "    heat_map, superimposed_img = show_heatmap(model, new_X_test[i], y_test[i], pred_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.where(y_test == 0)[0]:\n",
    "    print('index ' + str(i));\n",
    "    heat_map, superimposed_img = show_heatmap(model, new_X_test[i], y_test[i], pred_test[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
